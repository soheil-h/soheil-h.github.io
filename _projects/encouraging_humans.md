---
layout: page
title: Encouraging Human-Robot Teams
description: Encouraging human interaction with robot teams
img: assets/img/projects/encouraging_humans/ra-l.jpg
importance: 5
category: PhD
---

Recent works explore collaboration between humans and teams of robots. These approaches make sense if the human is already working with the robot team; but how should robots encourage nearby humans to join their teams in the first place? Inspired by economics, we recognize that humans care about more than just team efficiency --- humans also have biases and expectations for team dynamics. Our hypothesis is that the way inclusive robots divide the task (i.e., how the robots split a larger task into subtask allocations) should be both <em>legible</em> and <em>fair</em> to the human partner. We introduce a bilevel optimization approach that enables robot teams to identify high-level subtask allocations and low-level trajectories that optimize for legibility, fairness, or a combination of both objectives. We then test our resulting algorithm across studies where humans <em>watch</em> or <em>play</em> with robot teams. We find that our approach to generating legible teams makes the humanâ€™s role clear, and that humans typically prefer to join and collaborate with legible teams instead of teams that only optimize for efficiency. Incorporating fairness alongside legibility further encourages participation: when humans play with robots, we find that they prefer (potentially inefficient) teams where the subtasks or effort are evenly divided.


<p align="center"><iframe width="560" height="315" src="https://www.youtube.com/embed/cfN7O5na3mg?rel=0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</p>
